{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T11:05:30.195762Z",
     "start_time": "2024-03-26T11:05:29.504590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = [0.9655139152197769, 5.051538138473209, -4.004896218606084, 7.021097556897876, 1.9976899691291532, -0.10373532944839803]\n",
      "\n",
      "Mean squared error (train): 1.4136786666328538\n",
      "Mean squared error (test): 1.4921846102530003\n",
      "\n",
      "Mean squared error (Lasso train): 1.4171483544297718\n",
      "Mean squared error (Lasso test): 1.4877102711352492\n",
      "\n",
      "Mean squared error (FFNN train): 1.4292493574382097\n",
      "Mean squared error (FFNN test): 1.4843785754299945\n",
      "\n",
      "Acc list: [0.996110490039906, 0.9965346028292097, 0.9966131719149666, 0.9967153535846587, 0.9955932783970327, 0.9964138669721551, 0.9971858294733027, 0.9964344919907442, 0.9965549765193799, 0.9959294402239626] \n",
      "\n",
      "MSE list (FFNN): [1.57414772000207, 1.5141132503112726, 1.4081307613291525, 1.4004800672502424, 1.6796240714897217, 1.5875890809687303, 1.3400804049396142, 1.6137613748092854, 1.4379775828767491, 1.7789186507179335]\n",
      "Best MSE (FFNN): 1.3400804049396142 \n",
      "\n",
      "MSE list (LR) [1.4574422562891953, 1.3838677287770684, 1.325472507308375, 1.2997789678391296, 1.602502758671767, 1.5372553715596462, 1.3114022500092937, 1.536465564833507, 1.4082122124937235, 1.5418429809165997]\n",
      "Best MSE (LR): 1.2997789678391296 \n",
      "\n",
      "mean (lr): 0.1475 -- s2: 0.12574375\n",
      "mean (nn): 0.15916666666666668 -- s2: 0.1338326388888889\n",
      "T = 0.023 -> within 95% confidence interval => accept null hypothesis, there is no significant difference between the means of two groups\n",
      "paired t-test: T=-1.10, p-value=0.2715\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import io\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# Load data \n",
    "url = 'https://drive.switch.ch/index.php/s/37RuoA3Mgt9Rqah/download'\n",
    "response = requests.get(url)\n",
    "data = np.load(io.BytesIO(response.content))\n",
    "\n",
    "\n",
    "# Alternatively you can load the data from file\n",
    "#data_path = 'data.npz' # path to the .npz file storing the data\n",
    "#data = np.load(data_path)\n",
    "\n",
    "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
    "x = data.f.x\n",
    "# y is a Numpy array of shape (n_samples, ) with the targets\n",
    "y = data.f.y\n",
    "\n",
    "# T1 \n",
    "# =================================== LINEAR REGRESSION =======================================\n",
    "# regularize data\n",
    "pol_feat_high = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X = pol_feat_high.fit_transform(x)\n",
    "\n",
    "# augment so it fits specified model\n",
    "x_aug = np.hstack((x, \n",
    "    np.cos(x[:,0]).reshape(-1,1),\n",
    "    (x[:,1]**2).reshape(-1,1),\n",
    "    (np.tanh(x[:,0]).reshape(-1,1))\n",
    "))\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, shuffle=True, random_state=0)\n",
    "\n",
    "# modify and reshape train/test input to fit our family of models\n",
    "x_train_aug = np.hstack((x_train, \n",
    "    np.cos(x_train[:,0]).reshape(-1,1),\n",
    "    (x_train[:,1]**2).reshape(-1,1),\n",
    "    (np.tanh(x_train[:,0]).reshape(-1,1))\n",
    "))\n",
    "\n",
    "x_test_aug = np.hstack((x_test, \n",
    "    np.cos(x_test[:,0]).reshape(-1,1),\n",
    "    (x_test[:,1]**2).reshape(-1,1),\n",
    "    (np.tanh(x_test[:,0]).reshape(-1,1))\n",
    "))\n",
    "\n",
    "# regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train_aug, y_train)\n",
    "\n",
    "theta = [lr.intercept_] + lr.coef_.tolist()\n",
    "print('theta = {}\\n'.format(theta))\n",
    "\n",
    "# mean squared error / performance measure\n",
    "train_pred = lr.predict(x_train_aug)\n",
    "test_pred = lr.predict(x_test_aug)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, train_pred)\n",
    "print(\"Mean squared error (train): {}\".format(mse_train))\n",
    "\n",
    "mse_test = mean_squared_error(y_test, test_pred)\n",
    "print(\"Mean squared error (test): {}\\n\".format(mse_test))\n",
    "\n",
    "with open('linear_regression.pickle', 'wb') as file:\n",
    "    pickle.dump(lr, file)\n",
    "# =================================== LASSO REGRESSION =======================================\n",
    "\n",
    "interval = np.linspace(-1, 2, 1000).reshape(1000,1)\n",
    "scaler = StandardScaler()\n",
    "sigma = 0.02;\n",
    "lasso = Lasso(sigma)\n",
    "lasso.fit(x_train_aug, y_train)\n",
    "\n",
    "lasso_train_pred = lasso.predict(x_train_aug)\n",
    "lasso_test_pred = lasso.predict(x_test_aug)\n",
    "\n",
    "lasso_mse_train = mean_squared_error(y_train, lasso_train_pred)\n",
    "print(\"Mean squared error (Lasso train): {}\".format(lasso_mse_train))\n",
    "\n",
    "lasso_mse_test = mean_squared_error(y_test, lasso_test_pred)\n",
    "print(\"Mean squared error (Lasso test): {}\\n\".format(lasso_mse_test))\n",
    "\n",
    "# T2\n",
    "# ================================== NON-LINEAR REGRESSION ====================================\n",
    "# regularize data\n",
    "pol_feat_high = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X = pol_feat_high.fit_transform(x)\n",
    "\n",
    "nn_kwargs= {\"hidden_layer_sizes\":(200,), # number of neurons\n",
    "            \"activation\":\"relu\",         # non-linear activation function (through all the network)\n",
    "            \"max_iter\":250,              # epochs\n",
    "            \"solver\":\"adam\",             # optimizer\n",
    "            \"random_state\": 42}\n",
    "\n",
    "ffnn = MLPRegressor(**nn_kwargs)\n",
    "\n",
    "X = np.vstack(X)\n",
    "X_train, X_test, y_train_ffnn, y_test_ffnn = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=0)\n",
    "\n",
    "ffnn.fit(X, y)\n",
    "\n",
    "ffnn_train_pred = ffnn.predict(X_train)\n",
    "ffnn_test_pred = ffnn.predict(X_test)\n",
    "\n",
    "ffnn_mse_train = mean_squared_error(y_train_ffnn, ffnn_train_pred)\n",
    "print(\"Mean squared error (FFNN train): {}\".format(ffnn_mse_train))\n",
    "\n",
    "ffnn_mse_test = mean_squared_error(y_test_ffnn, ffnn_test_pred)\n",
    "print(\"Mean squared error (FFNN test): {}\\n\".format(ffnn_mse_test))\n",
    "\n",
    "with open('nonlinear_model.pickle', 'wb') as file:\n",
    "    pickle.dump(ffnn, file)\n",
    "# =================================== CROSS VALIDATION =======================================\n",
    "# Split the data\n",
    "kfcv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_iterator = kfcv.split(X, y)\n",
    "acc_nn = []\n",
    "mses = []\n",
    "\n",
    "# For FFNN\n",
    "for idx_train, idx_val in fold_iterator:\n",
    "    # split data\n",
    "    X_train_val, y_train_val = X[idx_train], y[idx_train]\n",
    "    X_val, y_val = X[idx_val], y[idx_val]\n",
    "    \n",
    "    # train model\n",
    "    ffnn = MLPRegressor(**nn_kwargs)\n",
    "    ffnn.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # calculate MSE\n",
    "    ffnn_val_pred = ffnn.predict(X_val)\n",
    "    ffnn_mse_val = mean_squared_error(y_val, ffnn_val_pred)\n",
    "    mses.append(ffnn_mse_val)\n",
    "    \n",
    "    # evaluate model\n",
    "    current_acc = ffnn.score(X_val, y_val)\n",
    "    acc_nn.append(current_acc)\n",
    "\n",
    "\n",
    "# For LR\n",
    "mses_lin = []\n",
    "fold_iterator = kfcv.split(x_aug, y)\n",
    "for idx_train, idx_val in fold_iterator:\n",
    "    X_train_val, y_train_val = x_aug[idx_train], y[idx_train]\n",
    "    X_val, y_val = x_aug[idx_val], y[idx_val]\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_val, y_train_val)\n",
    "    val_pred = lr.predict(X_val)\n",
    "    \n",
    "    mse_val = mean_squared_error(y_val, val_pred)\n",
    "    mses_lin.append(mse_val)\n",
    "\n",
    "print(\"Acc list:\", acc_nn, \"\\n\")\n",
    "print(\"MSE list (FFNN):\", mses)\n",
    "print(\"Best MSE (FFNN):\", min(mses), \"\\n\")\n",
    "print(\"MSE list (LR)\", mses_lin)\n",
    "print(\"Best MSE (LR):\", min(mses_lin), \"\\n\")\n",
    "# print(\"R-Squared score:  {:.3f} +/- {:.3f}\\n\".format(np.mean(acc_nn), np.std(acc_nn)))\n",
    "\n",
    "\n",
    "# =================================== T-TEST =======================================\n",
    "# Linear Regression\n",
    "# This function was defined to mitigate the problem with exactness \n",
    "# when comparing the test values and predicted values\n",
    "def isclose(a, b, rel_tol=1e-02, abs_tol=0.0):\n",
    "    return abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)\n",
    "\n",
    "pred = lr.predict(x_test_aug)\n",
    "e_lr = []\n",
    "\n",
    "# compare test values and predicted values\n",
    "for idx in range(0, len(y_test_ffnn)):\n",
    "    if isclose(y_test_ffnn[idx], pred[idx]):\n",
    "        e_lr.append(1)\n",
    "    else:\n",
    "        e_lr.append(0)\n",
    "e_lr = np.array(e_lr)\n",
    "mean_e_lr = e_lr.mean()\n",
    "s2_lr = mean_e_lr * (1 - mean_e_lr)\n",
    "print(\"mean (lr): {} -- s2: {}\".format(mean_e_lr, s2_lr))\n",
    "\n",
    "# FFNN\n",
    "nn_pred = ffnn.predict(X_test)\n",
    "e_nn = []\n",
    "# compare test values and predicted values\n",
    "for idx in range(0, len(y_test_ffnn)):\n",
    "    if isclose(y_test_ffnn[idx], nn_pred[idx]):\n",
    "        e_nn.append(1)\n",
    "    else:\n",
    "        e_nn.append(0)\n",
    "e_nn = np.array(e_nn)\n",
    "\n",
    "y_pred = (ffnn.predict(X_test)).astype(int)\n",
    "mean_e_nn = e_nn.mean()\n",
    "s2_nn = mean_e_nn * (1 - mean_e_nn)\n",
    "print(\"mean (nn): {} -- s2: {}\".format(mean_e_nn, s2_nn))\n",
    "\n",
    "# Test statistics\n",
    "N = np.shape(X)[1]\n",
    "n = int(N * .8)\n",
    "l = N - n\n",
    "\n",
    "T = (mean_e_nn - mean_e_lr)\n",
    "T /= np.sqrt( s2_nn / l + s2_lr / l )\n",
    "\n",
    "if -1.96 <= T <= 1.96:\n",
    "    print(\"T = {:.3f} -> within 95% confidence interval => accept null hypothesis, there is no significant difference between the means of two groups\".format(T))\n",
    "else:\n",
    "    print(\"T = {:.3f} -> not in 95% confidence interval => reject null hypothesis, there is significant difference between the means of two groups\".format(T))\n",
    "\n",
    "# paired t-test\n",
    "# The p-value is the probability of observing a test statistic given that the null hypothesis is true\n",
    "tt, p_val = ttest_rel(e_lr, e_nn)\n",
    "print('paired t-test: T={:.2f}, p-value={:.4f}'.format(tt, p_val))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff974a05601cd30",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 80\u001b[0m\n\u001b[1;32m     72\u001b[0m y_pred_yours \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m############################################################################\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# STOP EDITABLE SECTION: do not modify anything below this point.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m############################################################################\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Evaluate the prediction using MSE\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_yours\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE on whole dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# NOTE: NOW THIS CELL IS NOT WORKING SINCE YOU NEED TO CHANGE THE INPUT.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# DO IT AND EVERYTHING RUNS SMOOTH\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mevaluate_predictions\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_predictions\u001b[39m(y_true, y_pred):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Evaluates the mean squared error between the values in y_true and the values\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    in y_pred.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    :return: float, the mean squared error between the two arrays.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43my_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m==\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Import libraries\n",
    "import io\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluates the mean squared error between the values in y_true and the values\n",
    "    in y_pred.\n",
    "    ### YOU CAN NOT EDIT THIS FUNCTION ###\n",
    "    :param y_true: Numpy array, the true target values from the test set;\n",
    "    :param y_pred: Numpy array, the values predicted by your model.\n",
    "    :return: float, the mean squared error between the two arrays.\n",
    "    \"\"\"\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Loads a torch model saved.\n",
    "    This is just an example, you can write your own function to load the model.\n",
    "    Some examples can be found in src/utils.py.\n",
    "    :param filename: string, path to the file storing the model.\n",
    "    :return: the model.\n",
    "    \"\"\"\n",
    "    model = torch.jit.load(filename)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the data\n",
    "# This will be replaced with our private test data when grading the assignment\n",
    "\n",
    "# Load data from url\n",
    "url = 'https://drive.switch.ch/index.php/s/Wp0I2gb33mhERFN/download'\n",
    "response = requests.get(url)\n",
    "data = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# Alternatively yo can load the data from file\n",
    "#data_path = 'data_bonus_test.npz'\n",
    "#data = np.load(data_path)\n",
    "\n",
    "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
    "x = torch.tensor(data.f.x, dtype=torch.float32)\n",
    "# y is a Numpy array of shape (n_samples, ) with the targets\n",
    "y =  torch.tensor(data.f.y,dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Load the trained model\n",
    "baseline_model_path = r'Torch Model/baseline.pt'\n",
    "baseline_model = load_model(baseline_model_path)\n",
    "\n",
    "# Predict on the given samples\n",
    "y_pred_ours = baseline_model(x)\n",
    "\n",
    "############################################################################\n",
    "# STOP EDITABLE SECTION: DO NOT modify anything above this point.\n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "# ADD HERE YOUR CODE TO READ MODEL OF TASK 3\n",
    "############################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "baseline_model_path = 'YOUR_MODEL_PATH'\n",
    "baseline_model =  ...   # LOAD YOU MODEL and predict x\n",
    "# Predict on the given samples FROM YOUR MODEL\n",
    "y_pred_yours = ...\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# STOP EDITABLE SECTION: do not modify anything below this point.\n",
    "############################################################################\n",
    "\n",
    "# Evaluate the prediction using MSE\n",
    "mse = evaluate_predictions(y_pred_yours, y)\n",
    "print(f'MSE on whole dataset: {mse}')\n",
    "\n",
    "# NOTE: NOW THIS CELL IS NOT WORKING SINCE YOU NEED TO CHANGE THE INPUT.\n",
    "# DO IT AND EVERYTHING RUNS SMOOTH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
